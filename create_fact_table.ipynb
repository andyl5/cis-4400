{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL Complaint Facts\n",
    "# If using the native Google BigQuery API module:\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound\n",
    "# import credentials\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyarrow\n",
    "from datetime import datetime\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the GCP Project, dataset and table name\n",
    "gcp_project = 'cis-4400-404715'\n",
    "bq_dataset = '311_illegal_parking'\n",
    "\n",
    "path_to_service_account_key_file = 'keys.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data( df):\n",
    "    \"\"\"\n",
    "    transform_data\n",
    "    Accepts a data frame\n",
    "    Performs any specific cleaning and transformation steps on the dataframe\n",
    "    Returns the modified dataframe\n",
    "    \"\"\"\n",
    "    # Convert the date_of_birth to a datetime64 data type. 2012-08-21 04:12:16.827\n",
    "    df['date_of_birth'] = pd.to_datetime(df['date_of_birth'], format='%m/%d/%Y')\n",
    "    # Convert the postal code into a string\n",
    "    df['incident_zip'] =  df['incident_zip'].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_bigquery_table(bqclient, table_path, write_disposition, df):\n",
    "    \"\"\"\n",
    "    upload_bigquery_table\n",
    "    Accepts a path to a BigQuery table, the write disposition and a dataframe\n",
    "    Loads the data into the BigQuery table from the dataframe.\n",
    "    for credentials.\n",
    "    The write disposition is either\n",
    "    write_disposition=\"WRITE_TRUNCATE\"  Erase the target data and load all new data.\n",
    "    write_disposition=\"WRITE_APPEND\"    Append to the existing table\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        job_config = bigquery.LoadJobConfig(write_disposition=write_disposition)\n",
    "        \n",
    "        # Submit the job\n",
    "        job = bqclient.load_table_from_dataframe(df, table_path, job_config=job_config)\n",
    "        \n",
    "        # Show the job results\n",
    "        job.result()\n",
    "    except Exception as err:\n",
    "        print(\"Failed to load BigQuery Table.\", err)\n",
    "        # os._exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigquery_table_exists(table_path, bqclient):\n",
    "    \"\"\"\n",
    "    bigquery_table_exists\n",
    "    Accepts a path to a BigQuery table\n",
    "    Checks if the BigQuery table exists.\n",
    "    Returns True or False\n",
    "    \"\"\"\n",
    "    try:\n",
    "        bqclient.get_table(table_path)  # Make an API request.\n",
    "        return True\n",
    "    except NotFound:\n",
    "        # print(\"Table {} is not found.\".format(table_id))\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_new_table(bqclient, table_path, df):\n",
    "    \"\"\"\n",
    "    build_new_table\n",
    "    Accepts a path to a dimensional table, the dimension name and a data frame\n",
    "    Add the surrogate key and a record timestamp to the data frame\n",
    "    Inserts the contents of the dataframe to the dimensional table.\n",
    "    \"\"\"\n",
    "    upload_bigquery_table(bqclient, table_path, \"WRITE_TRUNCATE\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_existing_table( bqclient, table_path, df):\n",
    "    \"\"\"\n",
    "    insert_existing_table\n",
    "    Accepts a path to a dimensional table, the dimension name and a data frame\n",
    "    Compares the new data to the existing data in the table.\n",
    "    Inserts the new/modified records to the existing table\n",
    "    \"\"\"\n",
    "    upload_bigquery_table( bqclient, table_path, \"WRITE_APPEND\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_bigquery_table(table_path, bqclient, surrogate_key):\n",
    "    \"\"\"\n",
    "    query_bigquery_table\n",
    "    Accepts a path to a BigQuery table and the name of the surrogate key\n",
    "    Queries the BigQuery table but leaves out the update_timestamp and surrogate key columns\n",
    "    Returns the dataframe\n",
    "    \"\"\"    \n",
    "    bq_df = pd.DataFrame\n",
    "    # sql_query = 'SELECT * EXCEPT ( update_timestamp, '+surrogate_key+') FROM `' + table_path + '`'\n",
    "    sql_query = 'SELECT * FROM `' + table_path + '`'\n",
    "    bq_df = bqclient.query(sql_query).to_dataframe()\n",
    "    return bq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension_lookup(dimension_name, lookup_columns, df):\n",
    "    \"\"\"\n",
    "    dimension_lookup\n",
    "    Lookup the lookup_columns in the dimension_name and return the associated surrogate keys\n",
    "    Returns dataframe augmented with the surrogate keys\n",
    "    \"\"\"\n",
    "    bq_df = pd.DataFrame\n",
    "    surrogate_key = dimension_name+\"_dim_id\"\n",
    "    dimension_table_path = \".\".join([gcp_project,bq_dataset,dimension_name+\"_dimension\"])\n",
    "    # Fetch the existing table\n",
    "    bq_df = query_bigquery_table(dimension_table_path, bqclient, surrogate_key)\n",
    "    if dimension_name == 'date':\n",
    "        bq_df['full_date'] = bq_df['full_date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "\n",
    "    print(bq_df)\n",
    "    # Melt the dimension dataframe into an index with the lookup columns\n",
    "    m = bq_df.melt(id_vars=lookup_columns, value_vars=surrogate_key)\n",
    "    print(m)\n",
    "    # Rename the \"value\" column to the surrogate key column name\n",
    "    m=m.rename(columns={\"value\":surrogate_key})\n",
    "    # Merge with the fact table record\n",
    "    df = df.merge(m, on=lookup_columns, how='left')\n",
    "    # Drop the \"variable\" column and the lookup columns\n",
    "    df = df.drop(columns=lookup_columns)\n",
    "    df = df.drop(columns=\"variable\")\n",
    "    #print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_column(df, bq_dataset, dimension_name):\n",
    "\n",
    "    # Renaming for 311\n",
    "    if bq_dataset == '311_illegal_parking':\n",
    "        if dimension_name == 'complaint':\n",
    "            df = df.rename(columns={'descriptor': 'complaint_description'})\n",
    "        elif dimension_name == 'complaint_source':\n",
    "            df = df.rename(columns={'open_data_channel_type': 'complaint_source_channel'})\n",
    "        elif dimension_name == 'location':\n",
    "            df = df.rename(columns={'city': 'incident_city', 'incident_zip': 'incident_zipcode'})\n",
    "        elif dimension_name == 'date':\n",
    "            df = df.rename(columns={'created_date': 'full_date'})\n",
    "\n",
    "    # Renaming for Open Parking\n",
    "    elif bq_dataset == 'open_parking':\n",
    "        if dimension_name == 'agency':\n",
    "            df = df.rename(columns={'issuing_agency': 'agency_name'})\n",
    "        elif dimension_name == 'location':\n",
    "            df = df.rename(columns={'precinct': 'precinct_num', 'county': 'borough'})\n",
    "        elif dimension_name == 'violation':\n",
    "            df = df.rename(columns={'violation': 'violation_description'})\n",
    "        elif dimension_name == 'violator':\n",
    "            df = df.rename(columns={'plate': 'violator_plate', 'state': 'violator_state'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_null_values(df, bq_dataset, dimension_name):\n",
    "    # Renaming for 311\n",
    "    if bq_dataset == '311_illegal_parking':\n",
    "      if dimension_name == 'location':\n",
    "        default_values = {\n",
    "          'city': 'Unspecified',\n",
    "          'incident_zip': 0,\n",
    "          'borough': 'Unspecified'\n",
    "        }\n",
    "        df.fillna(default_values, inplace=True)\n",
    "        \n",
    "    # Renaming for Open Parking\n",
    "    elif bq_dataset == 'open_parking':\n",
    "      if dimension_name == 'agency':\n",
    "        default_values = {\n",
    "          'issuing_agency': 'N/A'\n",
    "        }\n",
    "        df.fillna(default_values, inplace=True)\n",
    "\n",
    "      elif dimension_name == 'violation':\n",
    "        default_values = {\n",
    "          'violation_status': 'N/A'\n",
    "        }\n",
    "        df.fillna(default_values, inplace=True)\n",
    "\n",
    "      elif dimension_name == 'violator':\n",
    "        default_values = {\n",
    "          'plate': 'N/A'\n",
    "        }\n",
    "        df.fillna(default_values, inplace=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    complaint_dim_id   complaint_type           complaint_description\n",
      "0                  1  Illegal Parking                 Blocked Hydrant\n",
      "1                  2  Illegal Parking               Blocked Crosswalk\n",
      "2                  3  Illegal Parking   Posted Parking Sign Violation\n",
      "3                  4  Illegal Parking  Double Parked Blocking Traffic\n",
      "4                  5  Illegal Parking    Commercial Overnight Parking\n",
      "5                  6  Illegal Parking                Blocked Sidewalk\n",
      "6                  7  Illegal Parking     Parking Permit Improper Use\n",
      "7                  8  Illegal Parking  Double Parked Blocking Vehicle\n",
      "8                  9  Illegal Parking               Blocked Bike Lane\n",
      "9                 10  Illegal Parking        Unauthorized Bus Layover\n",
      "10                11  Illegal Parking    Overnight Commercial Storage\n",
      "11                12  Illegal Parking                Detached Trailer\n",
      "12                13  Illegal Parking            Paper License Plates\n",
      "13                14  Illegal Parking          License Plate Obscured\n",
      "     complaint_type           complaint_description          variable  value\n",
      "0   Illegal Parking                 Blocked Hydrant  complaint_dim_id      1\n",
      "1   Illegal Parking               Blocked Crosswalk  complaint_dim_id      2\n",
      "2   Illegal Parking   Posted Parking Sign Violation  complaint_dim_id      3\n",
      "3   Illegal Parking  Double Parked Blocking Traffic  complaint_dim_id      4\n",
      "4   Illegal Parking    Commercial Overnight Parking  complaint_dim_id      5\n",
      "5   Illegal Parking                Blocked Sidewalk  complaint_dim_id      6\n",
      "6   Illegal Parking     Parking Permit Improper Use  complaint_dim_id      7\n",
      "7   Illegal Parking  Double Parked Blocking Vehicle  complaint_dim_id      8\n",
      "8   Illegal Parking               Blocked Bike Lane  complaint_dim_id      9\n",
      "9   Illegal Parking        Unauthorized Bus Layover  complaint_dim_id     10\n",
      "10  Illegal Parking    Overnight Commercial Storage  complaint_dim_id     11\n",
      "11  Illegal Parking                Detached Trailer  complaint_dim_id     12\n",
      "12  Illegal Parking            Paper License Plates  complaint_dim_id     13\n",
      "13  Illegal Parking          License Plate Obscured  complaint_dim_id     14\n",
      "   complaint_source_dim_id complaint_source_channel\n",
      "0                        1                   ONLINE\n",
      "1                        2                   MOBILE\n",
      "2                        3                    PHONE\n",
      "3                        4                  UNKNOWN\n",
      "4                        5                    OTHER\n",
      "  complaint_source_channel                 variable  value\n",
      "0                   ONLINE  complaint_source_dim_id      1\n",
      "1                   MOBILE  complaint_source_dim_id      2\n",
      "2                    PHONE  complaint_source_dim_id      3\n",
      "3                  UNKNOWN  complaint_source_dim_id      4\n",
      "4                    OTHER  complaint_source_dim_id      5\n",
      "      date_dim_id   full_date  year  month month_name  day weekday_name\n",
      "0             337  2021-01-29  2021      1    January   29       Friday\n",
      "1             344  2021-01-22  2021      1    January   22       Friday\n",
      "2             351  2021-01-15  2021      1    January   15       Friday\n",
      "3             358  2021-01-08  2021      1    January    8       Friday\n",
      "4             365  2021-01-01  2021      1    January    1       Friday\n",
      "...           ...         ...   ...    ...        ...  ...          ...\n",
      "1063           31  2021-12-01  2021     12   December    1    Wednesday\n",
      "1064          369  2022-12-28  2022     12   December   28    Wednesday\n",
      "1065          376  2022-12-21  2022     12   December   21    Wednesday\n",
      "1066          383  2022-12-14  2022     12   December   14    Wednesday\n",
      "1067          390  2022-12-07  2022     12   December    7    Wednesday\n",
      "\n",
      "[1068 rows x 7 columns]\n",
      "       full_date  year  month month_name  day weekday_name     variable  value\n",
      "0     2021-01-29  2021      1    January   29       Friday  date_dim_id    337\n",
      "1     2021-01-22  2021      1    January   22       Friday  date_dim_id    344\n",
      "2     2021-01-15  2021      1    January   15       Friday  date_dim_id    351\n",
      "3     2021-01-08  2021      1    January    8       Friday  date_dim_id    358\n",
      "4     2021-01-01  2021      1    January    1       Friday  date_dim_id    365\n",
      "...          ...   ...    ...        ...  ...          ...          ...    ...\n",
      "1063  2021-12-01  2021     12   December    1    Wednesday  date_dim_id     31\n",
      "1064  2022-12-28  2022     12   December   28    Wednesday  date_dim_id    369\n",
      "1065  2022-12-21  2022     12   December   21    Wednesday  date_dim_id    376\n",
      "1066  2022-12-14  2022     12   December   14    Wednesday  date_dim_id    383\n",
      "1067  2022-12-07  2022     12   December    7    Wednesday  date_dim_id    390\n",
      "\n",
      "[1068 rows x 8 columns]\n",
      "     location_dim_id borough     incident_city  incident_zipcode\n",
      "0                419   BRONX             Bronx           10462.0\n",
      "1                437   BRONX          Brooklyn           10455.0\n",
      "2                441   BRONX            PELHAM           10803.0\n",
      "3                  2  QUEENS         RIDGEWOOD           11385.0\n",
      "4                  6  QUEENS           MASPETH           11378.0\n",
      "..               ...     ...               ...               ...\n",
      "436              166  QUEENS    QUEENS VILLAGE           11429.0\n",
      "437              215  QUEENS    QUEENS VILLAGE           11428.0\n",
      "438              247  QUEENS    QUEENS VILLAGE           11427.0\n",
      "439               48  QUEENS  LONG ISLAND CITY           11101.0\n",
      "440              184  QUEENS  LONG ISLAND CITY           11109.0\n",
      "\n",
      "[441 rows x 4 columns]\n",
      "    borough     incident_city  incident_zipcode         variable  value\n",
      "0     BRONX             Bronx           10462.0  location_dim_id    419\n",
      "1     BRONX          Brooklyn           10455.0  location_dim_id    437\n",
      "2     BRONX            PELHAM           10803.0  location_dim_id    441\n",
      "3    QUEENS         RIDGEWOOD           11385.0  location_dim_id      2\n",
      "4    QUEENS           MASPETH           11378.0  location_dim_id      6\n",
      "..      ...               ...               ...              ...    ...\n",
      "436  QUEENS    QUEENS VILLAGE           11429.0  location_dim_id    166\n",
      "437  QUEENS    QUEENS VILLAGE           11428.0  location_dim_id    215\n",
      "438  QUEENS    QUEENS VILLAGE           11427.0  location_dim_id    247\n",
      "439  QUEENS  LONG ISLAND CITY           11101.0  location_dim_id     48\n",
      "440  QUEENS  LONG ISLAND CITY           11109.0  location_dim_id    184\n",
      "\n",
      "[441 rows x 5 columns]\n",
      "   status_dim_id       status\n",
      "0              1       Closed\n",
      "1              2  Unspecified\n",
      "2              3  In Progress\n",
      "        status       variable  value\n",
      "0       Closed  status_dim_id      1\n",
      "1  Unspecified  status_dim_id      2\n",
      "2  In Progress  status_dim_id      3\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = pd.DataFrame\n",
    "    # Create the BigQuery Client\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = path_to_service_account_key_file\n",
    "\n",
    "    # Construct a BigQuery client object\n",
    "    bqclient = bigquery.Client()\n",
    "    \n",
    "    fact_name = '311_illegal_parking'\n",
    "    table_name = fact_name + '_fact'\n",
    "    # Construct the full BigQuery path to the table\n",
    "    fact_table_path = \".\".join([gcp_project,bq_dataset,table_name])\n",
    "    file_source_path = 'data/311_master.csv'\n",
    "\n",
    "    # Load in the data file\n",
    "    with open(file_source_path, 'r') as data:\n",
    "            df = pd.read_csv(data)\n",
    "    # Set all of the column names to lower case letters\n",
    "    df = df.rename(columns=str.lower)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'complaint')\n",
    "    df = dimension_lookup(dimension_name='complaint', lookup_columns=['complaint_type', 'complaint_description'], df=df)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'complaint_source') \n",
    "    df = dimension_lookup(dimension_name='complaint_source', lookup_columns=['complaint_source_channel'], df=df)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'date') \n",
    "    # Convert column to datetime\n",
    "    df['full_date'] = pd.to_datetime(df['full_date'])\n",
    "    df['year'] = df['full_date'].dt.year\n",
    "    df['month'] = df['full_date'].dt.month\n",
    "    df['month_name'] = df['full_date'].dt.strftime('%B')\n",
    "    df['day'] = df['full_date'].dt.day\n",
    "    df['weekday_name'] = df['full_date'].dt.strftime('%A')\n",
    "    df['full_date'] = df['full_date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    df = dimension_lookup(dimension_name='date', lookup_columns=['full_date', 'year', 'month', 'month_name', 'day', 'weekday_name'], df=df)\n",
    "\n",
    "    df = handle_null_values(df, bq_dataset, 'location')\n",
    "    df = rename_column(df, bq_dataset, 'location') \n",
    "    df = dimension_lookup(dimension_name='location', lookup_columns=['borough', 'incident_city', 'incident_zipcode'], df=df)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'status') \n",
    "    df = dimension_lookup(dimension_name='status', lookup_columns=['status'], df=df)\n",
    "\n",
    "    # A list of all of the surrogate keys\n",
    "    # For transaction grain, also include the 'unique_key' column\n",
    "    surrogate_keys=['unique_key', 'complaint_dim_id','complaint_source_dim_id','date_dim_id','location_dim_id','status_dim_id']\n",
    "    \n",
    "    # Remove all of the other non-surrogate key columns\n",
    "    df = df[surrogate_keys]\n",
    "\n",
    "    # See if the target table exists\n",
    "    target_table_exists = bigquery_table_exists(fact_table_path, bqclient )\n",
    "    # If the target table does not exist, load all of the data into a new table\n",
    "    if not target_table_exists:\n",
    "        build_new_table( bqclient, fact_table_path, df)\n",
    "    # If the target table exists, then perform an incremental load\n",
    "    if target_table_exists:\n",
    "        insert_existing_table( bqclient, fact_table_path, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPEN PARKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = pd.DataFrame\n",
    "    # Create the BigQuery Client\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = path_to_service_account_key_file\n",
    "\n",
    "    # Construct a BigQuery client object\n",
    "    bqclient = bigquery.Client()\n",
    "\n",
    "    fact_name = 'open_parking'\n",
    "    table_name = fact_name + '_fact'\n",
    "    # Construct the full BigQuery path to the table\n",
    "    fact_table_path = \".\".join([gcp_project,bq_dataset,table_name])\n",
    "    file_source_path = 'data/open_parking_master.csv'\n",
    "\n",
    "    # Load in the data file\n",
    "    with open(file_source_path, 'r') as data:\n",
    "            df = pd.read_csv(data)\n",
    "    # Set all of the column names to lower case letters\n",
    "    df = df.rename(columns=str.lower)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'agency')\n",
    "    df = dimension_lookup(dimension_name='agency', lookup_columns=['agency_name'], df=df)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'date') \n",
    "    # Convert column to datetime\n",
    "    df['full_date'] = pd.to_datetime(df['full_date'])\n",
    "    df['year'] = df['full_date'].dt.year\n",
    "    df['month'] = df['full_date'].dt.month\n",
    "    df['month_name'] = df['full_date'].dt.strftime('%B')\n",
    "    df['day'] = df['full_date'].dt.day\n",
    "    df['weekday_name'] = df['full_date'].dt.strftime('%A')\n",
    "    df['full_date'] = df['full_date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    df = dimension_lookup(dimension_name='date', lookup_columns=['full_date', 'year', 'month', 'month_name', 'day', 'weekday_name'], df=df)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'location')\n",
    "    df = dimension_lookup(dimension_name='location', lookup_columns=['precinct_num', 'borough', 'incident_zipcode'], df=df)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'violation') \n",
    "    df = dimension_lookup(dimension_name='violation', lookup_columns=['violation_description', 'violation_status'], df=df)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'violator') \n",
    "    df = dimension_lookup(dimension_name='violator', lookup_columns=['violator_plate', 'violator_state', 'license_type'], df=df)\n",
    "\n",
    "    # A list of all of the surrogate keys\n",
    "    # For transaction grain, also include the 'unique_key' column\n",
    "    surrogate_keys=['unique_key', 'agency_dim_id', 'location_dim_id', 'date_dim_id', 'violation_dim_id', 'violator_dim_id']\n",
    "    \n",
    "    # Remove all of the other non-surrogate key columns\n",
    "    df = df[surrogate_keys]\n",
    "\n",
    "    # See if the target table exists\n",
    "    target_table_exists = bigquery_table_exists(fact_table_path, bqclient )\n",
    "    # If the target table does not exist, load all of the data into a new table\n",
    "    if not target_table_exists:\n",
    "        build_new_table( bqclient, fact_table_path, df)\n",
    "    # If the target table exists, then perform an incremental load\n",
    "    if target_table_exists:\n",
    "        insert_existing_table( bqclient, fact_table_path, df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
