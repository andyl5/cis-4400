{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL Complaint Facts\n",
    "# If using the native Google BigQuery API module:\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound\n",
    "# import credentials\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the GCP Project, dataset and table name\n",
    "gcp_project = 'cis-4400-404715'\n",
    "path_to_service_account_key_file = 'keys.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_bigquery_table(bqclient, table_path, write_disposition, df):\n",
    "    \"\"\"\n",
    "    upload_bigquery_table\n",
    "    Accepts a path to a BigQuery table, the write disposition and a dataframe\n",
    "    Loads the data into the BigQuery table from the dataframe.\n",
    "    for credentials.\n",
    "    The write disposition is either\n",
    "    write_disposition=\"WRITE_TRUNCATE\"  Erase the target data and load all new data.\n",
    "    write_disposition=\"WRITE_APPEND\"    Append to the existing table\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        job_config = bigquery.LoadJobConfig(write_disposition=write_disposition)\n",
    "        \n",
    "        # Submit the job\n",
    "        job = bqclient.load_table_from_dataframe(df, table_path, job_config=job_config)\n",
    "        \n",
    "        # Show the job results\n",
    "        job.result()\n",
    "    except Exception as err:\n",
    "        print(\"Failed to load BigQuery Table.\", err)\n",
    "        # os._exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigquery_table_exists(table_path, bqclient):\n",
    "    \"\"\"\n",
    "    bigquery_table_exists\n",
    "    Accepts a path to a BigQuery table\n",
    "    Checks if the BigQuery table exists.\n",
    "    Returns True or False\n",
    "    \"\"\"\n",
    "    try:\n",
    "        bqclient.get_table(table_path)  # Make an API request.\n",
    "        return True\n",
    "    except NotFound:\n",
    "        # print(\"Table {} is not found.\".format(table_id))\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_new_table(bqclient, table_path, df):\n",
    "    \"\"\"\n",
    "    build_new_table\n",
    "    Accepts a path to a dimensional table, the dimension name and a data frame\n",
    "    Add the surrogate key and a record timestamp to the data frame\n",
    "    Inserts the contents of the dataframe to the dimensional table.\n",
    "    \"\"\"\n",
    "    upload_bigquery_table(bqclient, table_path, \"WRITE_TRUNCATE\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_existing_table( bqclient, table_path, df):\n",
    "    \"\"\"\n",
    "    insert_existing_table\n",
    "    Accepts a path to a dimensional table, the dimension name and a data frame\n",
    "    Compares the new data to the existing data in the table.\n",
    "    Inserts the new/modified records to the existing table\n",
    "    \"\"\"\n",
    "    upload_bigquery_table( bqclient, table_path, \"WRITE_APPEND\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_bigquery_table(table_path, bqclient, surrogate_key):\n",
    "    \"\"\"\n",
    "    query_bigquery_table\n",
    "    Accepts a path to a BigQuery table and the name of the surrogate key\n",
    "    Queries the BigQuery table but leaves out the update_timestamp and surrogate key columns\n",
    "    Returns the dataframe\n",
    "    \"\"\"    \n",
    "    bq_df = pd.DataFrame\n",
    "    # sql_query = 'SELECT * EXCEPT ( update_timestamp, '+surrogate_key+') FROM `' + table_path + '`'\n",
    "    sql_query = 'SELECT * FROM `' + table_path + '`'\n",
    "    bq_df = bqclient.query(sql_query).to_dataframe()\n",
    "    return bq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension_lookup(dimension_name, lookup_columns, df):\n",
    "    \"\"\"\n",
    "    dimension_lookup\n",
    "    Lookup the lookup_columns in the dimension_name and return the associated surrogate keys\n",
    "    Returns dataframe augmented with the surrogate keys\n",
    "    \"\"\"\n",
    "    bq_df = pd.DataFrame\n",
    "    surrogate_key = dimension_name+\"_dim_id\"\n",
    "    dimension_table_path = \".\".join([gcp_project,bq_dataset,dimension_name+\"_dimension\"])\n",
    "    # Fetch the existing table\n",
    "    bq_df = query_bigquery_table(dimension_table_path, bqclient, surrogate_key)\n",
    "    if dimension_name == 'date':\n",
    "        bq_df['full_date'] = bq_df['full_date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "\n",
    "    print(bq_df)\n",
    "    # Melt the dimension dataframe into an index with the lookup columns\n",
    "    m = bq_df.melt(id_vars=lookup_columns, value_vars=surrogate_key)\n",
    "    print(m)\n",
    "    # Rename the \"value\" column to the surrogate key column name\n",
    "    m=m.rename(columns={\"value\":surrogate_key})\n",
    "    # Merge with the fact table record\n",
    "    df = df.merge(m, on=lookup_columns, how='left')\n",
    "    # Drop the \"variable\" column and the lookup columns\n",
    "    df = df.drop(columns=lookup_columns)\n",
    "    df = df.drop(columns=\"variable\")\n",
    "    #print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_column(df, bq_dataset, dimension_name):\n",
    "\n",
    "    # Renaming for 311\n",
    "    if bq_dataset == '311_illegal_parking':\n",
    "        if dimension_name == 'complaint':\n",
    "            df = df.rename(columns={'descriptor': 'complaint_description'})\n",
    "        elif dimension_name == 'complaint_source':\n",
    "            df = df.rename(columns={'open_data_channel_type': 'complaint_source_channel'})\n",
    "        elif dimension_name == 'location':\n",
    "            df = df.rename(columns={'city': 'incident_city', 'incident_zip': 'incident_zipcode'})\n",
    "        elif dimension_name == 'date':\n",
    "            df = df.rename(columns={'created_date': 'full_date'})\n",
    "\n",
    "    # Renaming for Open Parking\n",
    "    elif bq_dataset == 'open_parking':\n",
    "        if dimension_name == 'agency':\n",
    "            df = df.rename(columns={'issuing_agency': 'agency_name'})\n",
    "        elif dimension_name == 'date':\n",
    "            df = df.rename(columns={'issue_date': 'full_date'})\n",
    "        elif dimension_name == 'location':\n",
    "            df = df.rename(columns={'precinct': 'precinct_num', 'county': 'borough', 'zipcode': 'incident_zipcode'})\n",
    "        elif dimension_name == 'violation':\n",
    "            df = df.rename(columns={'violation': 'violation_description'})\n",
    "        elif dimension_name == 'violator':\n",
    "            df = df.rename(columns={'plate': 'violator_plate', 'state': 'violator_state'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_null_values(df, bq_dataset, dimension_name):\n",
    "    # Renaming for 311\n",
    "    if bq_dataset == '311_illegal_parking':\n",
    "      if dimension_name == 'location':\n",
    "        default_values = {\n",
    "          'city': 'Unspecified',\n",
    "          'incident_zip': 0,\n",
    "          'borough': 'Unspecified'\n",
    "        }\n",
    "        df.fillna(default_values, inplace=True)\n",
    "        \n",
    "    # Renaming for Open Parking\n",
    "    elif bq_dataset == 'open_parking':\n",
    "      if dimension_name == 'agency':\n",
    "        default_values = {\n",
    "          'issuing_agency': 'N/A'\n",
    "        }\n",
    "        df.fillna(default_values, inplace=True)\n",
    "\n",
    "      elif dimension_name == 'violation':\n",
    "        default_values = {\n",
    "          'violation_status': 'N/A'\n",
    "        }\n",
    "        df.fillna(default_values, inplace=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_location_attributes(df):\n",
    "    precinct_to_zipcode = {\n",
    "        1: 10013,\n",
    "        5: 10013,\n",
    "        6: 10014,\n",
    "        7: 10002,\n",
    "        9: 10003,\n",
    "        10: 10011,\n",
    "        13: 10010,\n",
    "        14: 10001,\n",
    "        17: 10022,\n",
    "        18: 10019,\n",
    "        19: 10065,\n",
    "        20: 10024,\n",
    "        22: 10024,\n",
    "        23: 10029,\n",
    "        24: 10025,\n",
    "        25: 10035,\n",
    "        26: 10027,\n",
    "        28: 10027,\n",
    "        30: 10031,\n",
    "        32: 10030,\n",
    "        33: 10032,\n",
    "        34: 10033,\n",
    "        40: 10454,\n",
    "        41: 10459,\n",
    "        42: 10451,\n",
    "        43: 10473,\n",
    "        44: 10452,\n",
    "        45: 10465,\n",
    "        46: 10457,\n",
    "        47: 10466,\n",
    "        48: 10457,\n",
    "        49: 10461,\n",
    "        50: 10463,\n",
    "        52: 10467,\n",
    "        60: 11224,\n",
    "        61: 11223,\n",
    "        62: 11214,\n",
    "        63: 11210,\n",
    "        66: 11204,\n",
    "        67: 11226,\n",
    "        68: 11220,\n",
    "        69: 11236,\n",
    "        70: 11230,\n",
    "        71: 11225,\n",
    "        72: 11232,\n",
    "        73: 11212,\n",
    "        75: 11208,\n",
    "        76: 11231,\n",
    "        77: 11213,\n",
    "        78: 11217,\n",
    "        79: 11216,\n",
    "        81: 11221,\n",
    "        83: 11237,\n",
    "        84: 11201,\n",
    "        88: 11205,\n",
    "        90: 11211,\n",
    "        94: 11222,\n",
    "        100: 11693,\n",
    "        101: 11691,\n",
    "        102: 11418,\n",
    "        103: 11432,\n",
    "        104: 11385,\n",
    "        105: 11428,\n",
    "        106: 11417,\n",
    "        107: 11365,\n",
    "        108: 11101,\n",
    "        109: 11354,\n",
    "        110: 11373,\n",
    "        111: 11361,\n",
    "        112: 11375,\n",
    "        113: 11434,\n",
    "        114: 11103,\n",
    "        115: 11372,\n",
    "        120: 10301,\n",
    "        121: 10314,\n",
    "        122: 10306,\n",
    "        123: 10307\n",
    "    }\n",
    "\n",
    "    zipcode_to_borough = {\n",
    "        10013: \"Manhattan\",\n",
    "        10014: \"Manhattan\",\n",
    "        10002: \"Manhattan\",\n",
    "        10003: \"Manhattan\",\n",
    "        10011: \"Manhattan\",\n",
    "        10010: \"Manhattan\",\n",
    "        10001: \"Manhattan\",\n",
    "        10022: \"Manhattan\",\n",
    "        10019: \"Manhattan\",\n",
    "        10065: \"Manhattan\",\n",
    "        10024: \"Manhattan\",\n",
    "        10029: \"Manhattan\",\n",
    "        10025: \"Manhattan\",\n",
    "        10035: \"Manhattan\",\n",
    "        10027: \"Manhattan\",\n",
    "        10031: \"Manhattan\",\n",
    "        10030: \"Manhattan\",\n",
    "        10032: \"Manhattan\",\n",
    "        10033: \"Manhattan\",\n",
    "        10454: \"Bronx\",\n",
    "        10459: \"Bronx\",\n",
    "        10451: \"Bronx\",\n",
    "        10473: \"Bronx\",\n",
    "        10452: \"Bronx\",\n",
    "        10465: \"Bronx\",\n",
    "        10457: \"Bronx\",\n",
    "        10466: \"Bronx\",\n",
    "        10461: \"Bronx\",\n",
    "        10463: \"Bronx\",\n",
    "        10467: \"Bronx\",\n",
    "        11224: \"Brooklyn\",\n",
    "        11223: \"Brooklyn\",\n",
    "        11214: \"Brooklyn\",\n",
    "        11210: \"Brooklyn\",\n",
    "        11204: \"Brooklyn\",\n",
    "        11226: \"Brooklyn\",\n",
    "        11220: \"Brooklyn\",\n",
    "        11236: \"Brooklyn\",\n",
    "        11230: \"Brooklyn\",\n",
    "        11225: \"Brooklyn\",\n",
    "        11232: \"Brooklyn\",\n",
    "        11212: \"Brooklyn\",\n",
    "        11208: \"Brooklyn\",\n",
    "        11231: \"Brooklyn\",\n",
    "        11213: \"Brooklyn\",\n",
    "        11217: \"Brooklyn\",\n",
    "        11216: \"Brooklyn\",\n",
    "        11221: \"Brooklyn\",\n",
    "        11237: \"Brooklyn\",\n",
    "        11201: \"Brooklyn\",\n",
    "        11205: \"Brooklyn\",\n",
    "        11211: \"Brooklyn\",\n",
    "        11222: \"Brooklyn\",\n",
    "        11693: \"Queens\",\n",
    "        11691: \"Queens\",\n",
    "        11418: \"Queens\",\n",
    "        11432: \"Queens\",\n",
    "        11385: \"Queens\",\n",
    "        11428: \"Queens\",\n",
    "        11417: \"Queens\",\n",
    "        11365: \"Queens\",\n",
    "        11101: \"Queens\",\n",
    "        11354: \"Queens\",\n",
    "        11373: \"Queens\",\n",
    "        11361: \"Queens\",\n",
    "        11375: \"Queens\",\n",
    "        11434: \"Queens\",\n",
    "        11103: \"Queens\",\n",
    "        11372: \"Queens\",\n",
    "        10301: \"Staten Island\",\n",
    "        10314: \"Staten Island\",\n",
    "        10306: \"Staten Island\",\n",
    "        10307: \"Staten Island\"\n",
    "    }\n",
    "\n",
    "    df['incident_zipcode'] = df['precinct_num'].map(precinct_to_zipcode)\n",
    "    df['borough'] = df['incident_zipcode'].map(zipcode_to_borough)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fact table for 311 illegal parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    complaint_dim_id   complaint_type           complaint_description\n",
      "0                  1  Illegal Parking                 Blocked Hydrant\n",
      "1                  2  Illegal Parking               Blocked Crosswalk\n",
      "2                  3  Illegal Parking   Posted Parking Sign Violation\n",
      "3                  4  Illegal Parking  Double Parked Blocking Traffic\n",
      "4                  5  Illegal Parking    Commercial Overnight Parking\n",
      "5                  6  Illegal Parking                Blocked Sidewalk\n",
      "6                  7  Illegal Parking     Parking Permit Improper Use\n",
      "7                  8  Illegal Parking  Double Parked Blocking Vehicle\n",
      "8                  9  Illegal Parking               Blocked Bike Lane\n",
      "9                 10  Illegal Parking        Unauthorized Bus Layover\n",
      "10                11  Illegal Parking    Overnight Commercial Storage\n",
      "11                12  Illegal Parking                Detached Trailer\n",
      "12                13  Illegal Parking            Paper License Plates\n",
      "13                14  Illegal Parking          License Plate Obscured\n",
      "     complaint_type           complaint_description          variable  value\n",
      "0   Illegal Parking                 Blocked Hydrant  complaint_dim_id      1\n",
      "1   Illegal Parking               Blocked Crosswalk  complaint_dim_id      2\n",
      "2   Illegal Parking   Posted Parking Sign Violation  complaint_dim_id      3\n",
      "3   Illegal Parking  Double Parked Blocking Traffic  complaint_dim_id      4\n",
      "4   Illegal Parking    Commercial Overnight Parking  complaint_dim_id      5\n",
      "5   Illegal Parking                Blocked Sidewalk  complaint_dim_id      6\n",
      "6   Illegal Parking     Parking Permit Improper Use  complaint_dim_id      7\n",
      "7   Illegal Parking  Double Parked Blocking Vehicle  complaint_dim_id      8\n",
      "8   Illegal Parking               Blocked Bike Lane  complaint_dim_id      9\n",
      "9   Illegal Parking        Unauthorized Bus Layover  complaint_dim_id     10\n",
      "10  Illegal Parking    Overnight Commercial Storage  complaint_dim_id     11\n",
      "11  Illegal Parking                Detached Trailer  complaint_dim_id     12\n",
      "12  Illegal Parking            Paper License Plates  complaint_dim_id     13\n",
      "13  Illegal Parking          License Plate Obscured  complaint_dim_id     14\n",
      "   complaint_source_dim_id complaint_source_channel\n",
      "0                        1                   ONLINE\n",
      "1                        2                   MOBILE\n",
      "2                        3                    PHONE\n",
      "3                        4                  UNKNOWN\n",
      "4                        5                    OTHER\n",
      "  complaint_source_channel                 variable  value\n",
      "0                   ONLINE  complaint_source_dim_id      1\n",
      "1                   MOBILE  complaint_source_dim_id      2\n",
      "2                    PHONE  complaint_source_dim_id      3\n",
      "3                  UNKNOWN  complaint_source_dim_id      4\n",
      "4                    OTHER  complaint_source_dim_id      5\n",
      "      date_dim_id   full_date  year  month month_name  day weekday_name\n",
      "0             337  2021-01-29  2021      1    January   29       Friday\n",
      "1             344  2021-01-22  2021      1    January   22       Friday\n",
      "2             351  2021-01-15  2021      1    January   15       Friday\n",
      "3             358  2021-01-08  2021      1    January    8       Friday\n",
      "4             365  2021-01-01  2021      1    January    1       Friday\n",
      "...           ...         ...   ...    ...        ...  ...          ...\n",
      "1063           31  2021-12-01  2021     12   December    1    Wednesday\n",
      "1064          369  2022-12-28  2022     12   December   28    Wednesday\n",
      "1065          376  2022-12-21  2022     12   December   21    Wednesday\n",
      "1066          383  2022-12-14  2022     12   December   14    Wednesday\n",
      "1067          390  2022-12-07  2022     12   December    7    Wednesday\n",
      "\n",
      "[1068 rows x 7 columns]\n",
      "       full_date  year  month month_name  day weekday_name     variable  value\n",
      "0     2021-01-29  2021      1    January   29       Friday  date_dim_id    337\n",
      "1     2021-01-22  2021      1    January   22       Friday  date_dim_id    344\n",
      "2     2021-01-15  2021      1    January   15       Friday  date_dim_id    351\n",
      "3     2021-01-08  2021      1    January    8       Friday  date_dim_id    358\n",
      "4     2021-01-01  2021      1    January    1       Friday  date_dim_id    365\n",
      "...          ...   ...    ...        ...  ...          ...          ...    ...\n",
      "1063  2021-12-01  2021     12   December    1    Wednesday  date_dim_id     31\n",
      "1064  2022-12-28  2022     12   December   28    Wednesday  date_dim_id    369\n",
      "1065  2022-12-21  2022     12   December   21    Wednesday  date_dim_id    376\n",
      "1066  2022-12-14  2022     12   December   14    Wednesday  date_dim_id    383\n",
      "1067  2022-12-07  2022     12   December    7    Wednesday  date_dim_id    390\n",
      "\n",
      "[1068 rows x 8 columns]\n",
      "     location_dim_id borough     incident_city  incident_zipcode\n",
      "0                419   BRONX             Bronx           10462.0\n",
      "1                437   BRONX          Brooklyn           10455.0\n",
      "2                441   BRONX            PELHAM           10803.0\n",
      "3                  2  QUEENS         RIDGEWOOD           11385.0\n",
      "4                  6  QUEENS           MASPETH           11378.0\n",
      "..               ...     ...               ...               ...\n",
      "436              166  QUEENS    QUEENS VILLAGE           11429.0\n",
      "437              215  QUEENS    QUEENS VILLAGE           11428.0\n",
      "438              247  QUEENS    QUEENS VILLAGE           11427.0\n",
      "439               48  QUEENS  LONG ISLAND CITY           11101.0\n",
      "440              184  QUEENS  LONG ISLAND CITY           11109.0\n",
      "\n",
      "[441 rows x 4 columns]\n",
      "    borough     incident_city  incident_zipcode         variable  value\n",
      "0     BRONX             Bronx           10462.0  location_dim_id    419\n",
      "1     BRONX          Brooklyn           10455.0  location_dim_id    437\n",
      "2     BRONX            PELHAM           10803.0  location_dim_id    441\n",
      "3    QUEENS         RIDGEWOOD           11385.0  location_dim_id      2\n",
      "4    QUEENS           MASPETH           11378.0  location_dim_id      6\n",
      "..      ...               ...               ...              ...    ...\n",
      "436  QUEENS    QUEENS VILLAGE           11429.0  location_dim_id    166\n",
      "437  QUEENS    QUEENS VILLAGE           11428.0  location_dim_id    215\n",
      "438  QUEENS    QUEENS VILLAGE           11427.0  location_dim_id    247\n",
      "439  QUEENS  LONG ISLAND CITY           11101.0  location_dim_id     48\n",
      "440  QUEENS  LONG ISLAND CITY           11109.0  location_dim_id    184\n",
      "\n",
      "[441 rows x 5 columns]\n",
      "   status_dim_id       status\n",
      "0              1       Closed\n",
      "1              2  Unspecified\n",
      "2              3  In Progress\n",
      "        status       variable  value\n",
      "0       Closed  status_dim_id      1\n",
      "1  Unspecified  status_dim_id      2\n",
      "2  In Progress  status_dim_id      3\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = pd.DataFrame\n",
    "    # Create the BigQuery Client\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = path_to_service_account_key_file\n",
    "\n",
    "    # Construct a BigQuery client object\n",
    "    bqclient = bigquery.Client()\n",
    "    \n",
    "    bq_dataset = '311_illegal_parking'\n",
    "    fact_name = '311_illegal_parking'\n",
    "    table_name = fact_name + '_fact'\n",
    "    # Construct the full BigQuery path to the table\n",
    "    fact_table_path = \".\".join([gcp_project,bq_dataset,table_name])\n",
    "    file_source_path = 'data/311_master.csv'\n",
    "\n",
    "    # Load in the data file\n",
    "    with open(file_source_path, 'r') as data:\n",
    "            df = pd.read_csv(data)\n",
    "   \n",
    "    # Set all of the column names to lower case letters\n",
    "    df = df.rename(columns=str.lower)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'complaint')\n",
    "    df = dimension_lookup(dimension_name='complaint', lookup_columns=['complaint_type', 'complaint_description'], df=df)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'complaint_source') \n",
    "    df = dimension_lookup(dimension_name='complaint_source', lookup_columns=['complaint_source_channel'], df=df)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'date') \n",
    "    df['full_date'] = pd.to_datetime(df['full_date'])\n",
    "    df['year'] = df['full_date'].dt.year\n",
    "    df['month'] = df['full_date'].dt.month\n",
    "    df['month_name'] = df['full_date'].dt.strftime('%B')\n",
    "    df['day'] = df['full_date'].dt.day\n",
    "    df['weekday_name'] = df['full_date'].dt.strftime('%A')\n",
    "    df['full_date'] = df['full_date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    df = dimension_lookup(dimension_name='date', lookup_columns=['full_date', 'year', 'month', 'month_name', 'day', 'weekday_name'], df=df)\n",
    "\n",
    "    df = handle_null_values(df, bq_dataset, 'location')\n",
    "    df = rename_column(df, bq_dataset, 'location') \n",
    "    df = dimension_lookup(dimension_name='location', lookup_columns=['borough', 'incident_city', 'incident_zipcode'], df=df)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'status') \n",
    "    df = dimension_lookup(dimension_name='status', lookup_columns=['status'], df=df)\n",
    "\n",
    "    # A list of all of the surrogate keys\n",
    "    # For transaction grain, also include the 'unique_key' column\n",
    "    surrogate_keys=['unique_key', 'complaint_dim_id','complaint_source_dim_id','date_dim_id','location_dim_id','status_dim_id']\n",
    "    \n",
    "    # Remove all of the other non-surrogate key columns\n",
    "    df = df[surrogate_keys]\n",
    "\n",
    "    # See if the target table exists\n",
    "    target_table_exists = bigquery_table_exists(fact_table_path, bqclient )\n",
    "    # If the target table does not exist, load all of the data into a new table\n",
    "    if not target_table_exists:\n",
    "        build_new_table( bqclient, fact_table_path, df)\n",
    "    # If the target table exists, then perform an incremental load\n",
    "    if target_table_exists:\n",
    "        insert_existing_table( bqclient, fact_table_path, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fact table for Open Parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    agency_dim_id                          agency_name\n",
      "0               1                              TRAFFIC\n",
      "1               2                    POLICE DEPARTMENT\n",
      "2               3             DEPARTMENT OF SANITATION\n",
      "3               4               OTHER/UNKNOWN AGENCIES\n",
      "4               5                     PARKS DEPARTMENT\n",
      "5               6                      FIRE DEPARTMENT\n",
      "6               7                       PORT AUTHORITY\n",
      "7               8       NYC TRANSIT AUTHORITY MANAGERS\n",
      "8               9                    TRANSIT AUTHORITY\n",
      "9              10                    HOUSING AUTHORITY\n",
      "10             11                    BOARD OF ESTIMATE\n",
      "11             12                   NYS COURT OFFICERS\n",
      "12             13                             CON RAIL\n",
      "13             14                 LONG ISLAND RAILROAD\n",
      "14             15            ROOSEVELT ISLAND SECURITY\n",
      "15             16     HEALTH AND HOSPITAL CORP. POLICE\n",
      "16             17  TRIBOROUGH BRIDGE AND TUNNEL POLICE\n",
      "17             18                 PARKING CONTROL UNIT\n",
      "18             19                     NYS PARKS POLICE\n",
      "19             20             HEALTH DEPARTMENT POLICE\n",
      "20             21        TAXI AND LIMOUSINE COMMISSION\n",
      "21             22             DEPARTMENT OF CORRECTION\n",
      "22             23            NYC OFFICE OF THE SHERIFF\n",
      "                            agency_name       variable  value\n",
      "0                               TRAFFIC  agency_dim_id      1\n",
      "1                     POLICE DEPARTMENT  agency_dim_id      2\n",
      "2              DEPARTMENT OF SANITATION  agency_dim_id      3\n",
      "3                OTHER/UNKNOWN AGENCIES  agency_dim_id      4\n",
      "4                      PARKS DEPARTMENT  agency_dim_id      5\n",
      "5                       FIRE DEPARTMENT  agency_dim_id      6\n",
      "6                        PORT AUTHORITY  agency_dim_id      7\n",
      "7        NYC TRANSIT AUTHORITY MANAGERS  agency_dim_id      8\n",
      "8                     TRANSIT AUTHORITY  agency_dim_id      9\n",
      "9                     HOUSING AUTHORITY  agency_dim_id     10\n",
      "10                    BOARD OF ESTIMATE  agency_dim_id     11\n",
      "11                   NYS COURT OFFICERS  agency_dim_id     12\n",
      "12                             CON RAIL  agency_dim_id     13\n",
      "13                 LONG ISLAND RAILROAD  agency_dim_id     14\n",
      "14            ROOSEVELT ISLAND SECURITY  agency_dim_id     15\n",
      "15     HEALTH AND HOSPITAL CORP. POLICE  agency_dim_id     16\n",
      "16  TRIBOROUGH BRIDGE AND TUNNEL POLICE  agency_dim_id     17\n",
      "17                 PARKING CONTROL UNIT  agency_dim_id     18\n",
      "18                     NYS PARKS POLICE  agency_dim_id     19\n",
      "19             HEALTH DEPARTMENT POLICE  agency_dim_id     20\n",
      "20        TAXI AND LIMOUSINE COMMISSION  agency_dim_id     21\n",
      "21             DEPARTMENT OF CORRECTION  agency_dim_id     22\n",
      "22            NYC OFFICE OF THE SHERIFF  agency_dim_id     23\n",
      "      date_dim_id   full_date    year  month month_name   day weekday_name\n",
      "0             215  2021-02-12  2021.0    2.0   February  12.0       Friday\n",
      "1             221  2021-02-26  2021.0    2.0   February  26.0       Friday\n",
      "2             281  2021-02-05  2021.0    2.0   February   5.0       Friday\n",
      "3             325  2021-02-19  2021.0    2.0   February  19.0       Friday\n",
      "4             437  2022-02-11  2022.0    2.0   February  11.0       Friday\n",
      "...           ...         ...     ...    ...        ...   ...          ...\n",
      "1058          645  2022-01-05  2022.0    1.0    January   5.0    Wednesday\n",
      "1059          862  2023-01-04  2023.0    1.0    January   4.0    Wednesday\n",
      "1060          918  2023-01-25  2023.0    1.0    January  25.0    Wednesday\n",
      "1061          934  2023-01-11  2023.0    1.0    January  11.0    Wednesday\n",
      "1062          965  2023-01-18  2023.0    1.0    January  18.0    Wednesday\n",
      "\n",
      "[1063 rows x 7 columns]\n",
      "       full_date    year  month month_name   day weekday_name     variable  \\\n",
      "0     2021-02-12  2021.0    2.0   February  12.0       Friday  date_dim_id   \n",
      "1     2021-02-26  2021.0    2.0   February  26.0       Friday  date_dim_id   \n",
      "2     2021-02-05  2021.0    2.0   February   5.0       Friday  date_dim_id   \n",
      "3     2021-02-19  2021.0    2.0   February  19.0       Friday  date_dim_id   \n",
      "4     2022-02-11  2022.0    2.0   February  11.0       Friday  date_dim_id   \n",
      "...          ...     ...    ...        ...   ...          ...          ...   \n",
      "1058  2022-01-05  2022.0    1.0    January   5.0    Wednesday  date_dim_id   \n",
      "1059  2023-01-04  2023.0    1.0    January   4.0    Wednesday  date_dim_id   \n",
      "1060  2023-01-25  2023.0    1.0    January  25.0    Wednesday  date_dim_id   \n",
      "1061  2023-01-11  2023.0    1.0    January  11.0    Wednesday  date_dim_id   \n",
      "1062  2023-01-18  2023.0    1.0    January  18.0    Wednesday  date_dim_id   \n",
      "\n",
      "      value  \n",
      "0       215  \n",
      "1       221  \n",
      "2       281  \n",
      "3       325  \n",
      "4       437  \n",
      "...     ...  \n",
      "1058    645  \n",
      "1059    862  \n",
      "1060    918  \n",
      "1061    934  \n",
      "1062    965  \n",
      "\n",
      "[1063 rows x 8 columns]\n",
      "    location_dim_id  precinct_num  incident_zipcode        borough\n",
      "0                 7            44           10452.0          Bronx\n",
      "1                27            46           10457.0          Bronx\n",
      "2                29            45           10465.0          Bronx\n",
      "3                36            42           10451.0          Bronx\n",
      "4                37            43           10473.0          Bronx\n",
      "..              ...           ...               ...            ...\n",
      "72               76            22           10024.0      Manhattan\n",
      "73               28           120           10301.0  Staten Island\n",
      "74               30           121           10314.0  Staten Island\n",
      "75               31           122           10306.0  Staten Island\n",
      "76               75           123           10307.0  Staten Island\n",
      "\n",
      "[77 rows x 4 columns]\n",
      "    precinct_num        borough  incident_zipcode         variable  value\n",
      "0             44          Bronx           10452.0  location_dim_id      7\n",
      "1             46          Bronx           10457.0  location_dim_id     27\n",
      "2             45          Bronx           10465.0  location_dim_id     29\n",
      "3             42          Bronx           10451.0  location_dim_id     36\n",
      "4             43          Bronx           10473.0  location_dim_id     37\n",
      "..           ...            ...               ...              ...    ...\n",
      "72            22      Manhattan           10024.0  location_dim_id     76\n",
      "73           120  Staten Island           10301.0  location_dim_id     28\n",
      "74           121  Staten Island           10314.0  location_dim_id     30\n",
      "75           122  Staten Island           10306.0  location_dim_id     31\n",
      "76           123  Staten Island           10307.0  location_dim_id     75\n",
      "\n",
      "[77 rows x 5 columns]\n",
      "     violation_dim_id           violation_description  \\\n",
      "0                  28                   ANGLE PARKING   \n",
      "1                  45                   ANGLE PARKING   \n",
      "2                  52                   ANGLE PARKING   \n",
      "3                  53                   ANGLE PARKING   \n",
      "4                  60                   ANGLE PARKING   \n",
      "..                ...                             ...   \n",
      "107               102  NO PARKING-EXC. HNDICAP PERMIT   \n",
      "108               104  NO PARKING-EXC. HNDICAP PERMIT   \n",
      "109               111  NO PARKING-EXC. HNDICAP PERMIT   \n",
      "110                94  OT PARKING-MISSING/BROKEN METR   \n",
      "111               112  OT PARKING-MISSING/BROKEN METR   \n",
      "\n",
      "                  violation_status  \n",
      "0                              N/A  \n",
      "1              HEARING HELD-GUILTY  \n",
      "2    HEARING HELD-GUILTY REDUCTION  \n",
      "3                  HEARING PENDING  \n",
      "4                  APPEAL AFFIRMED  \n",
      "..                             ...  \n",
      "107             ADMIN CLAIM DENIED  \n",
      "108                ADMIN REDUCTION  \n",
      "109                HEARING PENDING  \n",
      "110                            N/A  \n",
      "111            HEARING HELD-GUILTY  \n",
      "\n",
      "[112 rows x 3 columns]\n",
      "              violation_description               violation_status  \\\n",
      "0                     ANGLE PARKING                            N/A   \n",
      "1                     ANGLE PARKING            HEARING HELD-GUILTY   \n",
      "2                     ANGLE PARKING  HEARING HELD-GUILTY REDUCTION   \n",
      "3                     ANGLE PARKING                HEARING PENDING   \n",
      "4                     ANGLE PARKING                APPEAL AFFIRMED   \n",
      "..                              ...                            ...   \n",
      "107  NO PARKING-EXC. HNDICAP PERMIT             ADMIN CLAIM DENIED   \n",
      "108  NO PARKING-EXC. HNDICAP PERMIT                ADMIN REDUCTION   \n",
      "109  NO PARKING-EXC. HNDICAP PERMIT                HEARING PENDING   \n",
      "110  OT PARKING-MISSING/BROKEN METR                            N/A   \n",
      "111  OT PARKING-MISSING/BROKEN METR            HEARING HELD-GUILTY   \n",
      "\n",
      "             variable  value  \n",
      "0    violation_dim_id     28  \n",
      "1    violation_dim_id     45  \n",
      "2    violation_dim_id     52  \n",
      "3    violation_dim_id     53  \n",
      "4    violation_dim_id     60  \n",
      "..                ...    ...  \n",
      "107  violation_dim_id    102  \n",
      "108  violation_dim_id    104  \n",
      "109  violation_dim_id    111  \n",
      "110  violation_dim_id     94  \n",
      "111  violation_dim_id    112  \n",
      "\n",
      "[112 rows x 4 columns]\n",
      "     violator_dim_id violator_state license_type\n",
      "0                 79             99          999\n",
      "1                112             99          PAS\n",
      "2                121             99          OMT\n",
      "3                122             99          SRF\n",
      "4                124             99          COM\n",
      "..               ...            ...          ...\n",
      "161               32             VT          PAS\n",
      "162               27             WA          PAS\n",
      "163               67             WI          PAS\n",
      "164               33             WV          PAS\n",
      "165               69             WY          PAS\n",
      "\n",
      "[166 rows x 3 columns]\n",
      "    violator_state license_type         variable  value\n",
      "0               99          999  violator_dim_id     79\n",
      "1               99          PAS  violator_dim_id    112\n",
      "2               99          OMT  violator_dim_id    121\n",
      "3               99          SRF  violator_dim_id    122\n",
      "4               99          COM  violator_dim_id    124\n",
      "..             ...          ...              ...    ...\n",
      "161             VT          PAS  violator_dim_id     32\n",
      "162             WA          PAS  violator_dim_id     27\n",
      "163             WI          PAS  violator_dim_id     67\n",
      "164             WV          PAS  violator_dim_id     33\n",
      "165             WY          PAS  violator_dim_id     69\n",
      "\n",
      "[166 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = pd.DataFrame\n",
    "    # Create the BigQuery Client\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = path_to_service_account_key_file\n",
    "\n",
    "    # Construct a BigQuery client object\n",
    "    bqclient = bigquery.Client()\n",
    "\n",
    "    bq_dataset = 'open_parking'\n",
    "    fact_name = 'open_parking'\n",
    "    table_name = fact_name + '_fact'\n",
    "    # Construct the full BigQuery path to the table\n",
    "    fact_table_path = \".\".join([gcp_project,bq_dataset,table_name])\n",
    "    file_source_path = 'data/open_parking_master.csv'\n",
    "\n",
    "    # Load in the data file\n",
    "    with open(file_source_path, 'r') as data:\n",
    "            df = pd.read_csv(data)\n",
    "\n",
    "    # Set all of the column names to lower case letters\n",
    "    df = df.rename(columns=str.lower)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'agency')\n",
    "    df = dimension_lookup(dimension_name='agency', lookup_columns=['agency_name'], df=df)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'date') \n",
    "    df['full_date'] = pd.to_datetime(df['full_date'], format='%m/%d/%Y', errors='coerce')\n",
    "    df = df.dropna(subset=['full_date'], axis=0)\n",
    "    df['year'] = df['full_date'].dt.year\n",
    "    df['month'] = df['full_date'].dt.month\n",
    "    df['month_name'] = df['full_date'].dt.strftime('%B')\n",
    "    df['day'] = df['full_date'].dt.day\n",
    "    df['weekday_name'] = df['full_date'].dt.strftime('%A')\n",
    "    df['full_date'] = df['full_date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    df = dimension_lookup(dimension_name='date', lookup_columns=['full_date', 'year', 'month', 'month_name', 'day', 'weekday_name'], df=df)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'location')\n",
    "    df = calculate_location_attributes(df)\n",
    "    df = dimension_lookup(dimension_name='location', lookup_columns=['precinct_num', 'borough', 'incident_zipcode'], df=df)\n",
    "\n",
    "    df = handle_null_values(df, bq_dataset, 'violation')\n",
    "    df = rename_column(df, bq_dataset, 'violation') \n",
    "    df = dimension_lookup(dimension_name='violation', lookup_columns=['violation_description', 'violation_status'], df=df)\n",
    "\n",
    "    df = rename_column(df, bq_dataset, 'violator') \n",
    "    df = dimension_lookup(dimension_name='violator', lookup_columns=['violator_state', 'license_type'], df=df)\n",
    "\n",
    "    # A list of all of the surrogate keys\n",
    "    # For transaction grain, also include the 'unique_key' column\n",
    "    surrogate_keys=['summons_number', 'agency_dim_id', 'location_dim_id', 'date_dim_id', 'violation_dim_id', 'violator_dim_id']\n",
    "    \n",
    "    # Remove all of the other non-surrogate key columns\n",
    "    df = df[surrogate_keys]\n",
    "\n",
    "    # See if the target table exists\n",
    "    target_table_exists = bigquery_table_exists(fact_table_path, bqclient )\n",
    "    # If the target table does not exist, load all of the data into a new table\n",
    "    if not target_table_exists:\n",
    "        build_new_table( bqclient, fact_table_path, df)\n",
    "    # If the target table exists, then perform an incremental load\n",
    "    if target_table_exists:\n",
    "        insert_existing_table( bqclient, fact_table_path, df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
